# G-Transformer

This example is for ACL 2021 paper [G-Transformer for Document-level Machine Translation](https://aclanthology.org/2021.acl-long.267/).

## Pretrained Model
TODO

## Training your own model
Download iwslt17, nc2016, and europarl7 from [SAN](https://github.com/sameenmaruf/selective-attn/tree/master/data) and put them in this folder.


